#include <kern/arch.h>
#include <kern/lib.h>
#include <kern/pageinfo.h>
#include <inc/safeint.h>

static uint32_t membytes;	// Maximum usuable bytes of the physical AS
static char *boot_freemem;	// Pointer to next byte of free mem
static char *boot_endmem;       // Pointer to first unusable byte

// Keep track of various page metadata
struct page_info *page_infos;
uint32_t	 *page_bitmap;
uint32_t	  page_bitmap_words;

//
// Allocate n bytes of physical memory aligned on an
// align-byte boundary.  Align must be a power of two.
// Return kernel virtual address.  Returned memory is uninitialized.
//
// If we're out of memory, boot_alloc should panic.
// It's too early to run out of memory.
// This function may ONLY be used during initialization,
// before the page_free_list has been set up.
//
static void *
boot_alloc(uint32_t n, uint32_t align)
{
	extern char end[];
	void *v;

	if (boot_freemem == 0)
		boot_freemem = end;

	boot_freemem = (char *)ROUNDUP(boot_freemem, align);
	if (boot_freemem + n < boot_freemem || boot_freemem + n >= boot_endmem)
		panic ("boot_alloc: out of memory");

	v = boot_freemem;
	boot_freemem += n;

	return (v);
}

void
page_init(struct atag_mem *desc, int ndesc)
{
	extern char end[];
	int i;

	page_alloc_init();

	for (i = 0; i < ndesc; i++) {
		uint32_t s, e;

		s = ROUNDUP(desc[i].offset, PGSIZE);
		e = ROUNDDOWN(desc[i].offset + desc[i].bytes, PGSIZE);

		membytes += desc[i].bytes;

		// boot_alloc can only use memory from the contiguous physical
		// range that holds the kernel symbols.  'end' is a symbol
		// generated by the linker, which  points to the end of the
		// kernel's bss segment - i.e. the first virtual address that
		// the linker did _not_ assign to any kernel code or variables.
/* XXX - I think amd64/page.c has a bug if end == s */
		if (s <= RELOC(end) && e > RELOC(end)) {
			int oflow = 0;
			boot_freemem = end;
			boot_endmem = (char *)safe_addptr(&oflow, e, KERNBASE);
			if (oflow)
				boot_endmem = (char *)(uintptr_t)UINT32(~0);
		}

		// global_npages counts from 0 to the last RAM page.
		// The count may include unusable pages!
		if ((e / PGSIZE) > global_npages)
			global_npages = (e / PGSIZE);
	}

	// Align boot_freemem to page boundary.
	boot_alloc(0, PGSIZE);

	// Allocate space for page status info.
	uint64_t sz = global_npages * sizeof(*page_infos);
	page_infos = boot_alloc(sz, PGSIZE);
	memset(page_infos, 0, sz);

	// Create a bitmap to track all pages.
	// XXX- Any 64-bit archs with massive holes between chunks of main mem?
	uint32_t bmpgs = (global_npages + (PGSIZE * 8 - 1)) / (PGSIZE * 8);
	page_bitmap = (uint32_t *)boot_alloc(bmpgs * PGSIZE, PGSIZE);
	memset(page_bitmap, 0, bmpgs * PGSIZE);			//not free yet!
	page_bitmap_words = bmpgs * PGSIZE / sizeof(uint32_t);

	// Align to another page boundary.
	boot_alloc(0, PGSIZE);

	for (i = 0; i < ndesc; i++) {
		uint32_t s, e;

		s = ROUNDUP(desc[i].offset, PGSIZE);
		e = ROUNDDOWN(desc[i].offset + desc[i].bytes, PGSIZE);

		// NB: boot_freemem starts after the kernel, so we won't
		//     be putting exception vectors on the free list
		for (; s < e; s += PGSIZE) {
			if (s >= RELOC(boot_freemem))
				page_free(pa2kva(s));
		}
	}

	cprintf("Physical memory: %lluMB of %uMB available\n",
	    (page_stats.pages_avail << PGSHIFT) / (1024 * 1024),
	    membytes / (1024 * 1024));
	cprintf("Page bitmap: %uKB\n", (page_bitmap_words * 4) / 1024);

	page_stats.pages_used = 0;
}
